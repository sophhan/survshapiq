{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9116c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as pn\n",
    "# sksurv imports\n",
    "from sksurv.util import Surv as surv_util\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "# sklearn imports for data preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import concordance_index_censored as concordance\n",
    "# SurvSet package imports\n",
    "from SurvSet.data import SurvLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_group_split(df: pd.DataFrame, \n",
    "                           group_col: str ='pid', \n",
    "                           stratify_col: str ='event', \n",
    "                           test_frac: float = 0.2, \n",
    "                           seed: int | None = None):\n",
    "    '''\n",
    "    Function to make sure that patient IDs don't show up in both training and test sets. And then also balance the event rate across the two sets.\n",
    "    '''\n",
    "    # Step 1: Collapse to group-level (one row per patient)\n",
    "    group_df = df.groupby(group_col)[stratify_col].any().astype(int).reset_index()\n",
    "    # Step 2: Stratified split on the group level\n",
    "    group_train, group_test = train_test_split(\n",
    "        group_df,\n",
    "        stratify=group_df[stratify_col],\n",
    "        test_size=test_frac,\n",
    "        random_state=seed\n",
    "    )\n",
    "    # Step 3: Merge back to original data\n",
    "    df_train = df[df[group_col].isin(group_train[group_col])]\n",
    "    df_test = df[df[group_col].isin(group_test[group_col])]\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def bootstrap_concordance_index(\n",
    "    df: pd.DataFrame,\n",
    "    id_col: str = \"id\",\n",
    "    event_col: str = \"event\",\n",
    "    time_col: str = \"time\",\n",
    "    score_col: str = \"score\",\n",
    "    time2_col: str | None = None,\n",
    "    n_bs: int = 1000,\n",
    "    alpha: float = 0.05,\n",
    "    is_td: bool = False,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Wrapper on the concordance_index_timevarying function to perform bootstrap resampling for confidence intervals.\n",
    "    \"\"\"\n",
    "    # Input checks\n",
    "    expected_cols = [id_col, event_col, time_col, score_col]\n",
    "    if is_td:\n",
    "        expected_cols.append(time2_col)\n",
    "    missing_cols = np.setdiff1d(expected_cols, df.columns)\n",
    "    assert len(missing_cols) == 0, f\"Missing required columns: {missing_cols.tolist()}\"\n",
    "    assert isinstance(n_bs, int) and n_bs > 0, \"n_bs must be a positive integer.\"\n",
    "    assert 0 < alpha < 1, \"alpha must be between 0 and 1.\"\n",
    "    assert is_td in [True, False], \"is_td must be a boolean value.\"\n",
    "    # Subset to only the required columns\n",
    "    df = df[expected_cols].copy()\n",
    "    # Set up the storage holder and final DataFrame slice\n",
    "    holder_bs = np.zeros(n_bs)\n",
    "    # Get baseline result and then loop over the bootstrap samples\n",
    "    if is_td:\n",
    "        # Baseline\n",
    "        conc_test = concordance_index_timevarying(df, id_col, time_col, time2_col, event_col, score_col)\n",
    "        # Bootstrap\n",
    "        for j in range(n_bs):\n",
    "            res_bs = df.groupby(event_col).sample(frac=1,replace=True,random_state=j)\n",
    "            conc_bs = concordance_index_timevarying(res_bs, id_col, time_col, time2_col, event_col, score_col)\n",
    "            holder_bs[j] = conc_bs\n",
    "    else:\n",
    "        # Baseline\n",
    "        conc_test = concordance(df[event_col].astype(bool), df[time_col], df[score_col])[0]\n",
    "        # Bootstrap\n",
    "        for j in range(n_bs):\n",
    "            res_bs = df.groupby(event_col).sample(frac=1,replace=True,random_state=j)\n",
    "            conc_bs = concordance(res_bs[event_col].astype(bool), res_bs[time_col], res_bs[score_col])[0]\n",
    "            holder_bs[j] = conc_bs\n",
    "    # Add on the baseline result and empirical confidence intervals\n",
    "    lb, ub = np.quantile(holder_bs, [alpha,1-alpha])\n",
    "    holder_cindex = pd.DataFrame(np.atleast_2d((conc_test, lb, ub)), columns=['cindex', 'lb', 'ub'])\n",
    "    return holder_cindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a820c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure will saved here: /mnt/evafs/faculty/home/hbaniecki/survshapiq/experiments/results_survset\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# --- (1) PARAMETER SETUP --- #\n",
    "\n",
    "# Save to the examples directory\n",
    "dir_base = os.getcwd()\n",
    "dir_sim = os.path.join(dir_base, 'results_survset')\n",
    "if not os.path.isdir(dir_sim):\n",
    "    os.mkdir(dir_sim)\n",
    "print('Figure will saved here: %s' % dir_sim)\n",
    "\n",
    "# Concordance empirical alpha level\n",
    "alpha = 0.1\n",
    "# Number of bootstrap samples\n",
    "n_bs = 250\n",
    "# Set the random seed\n",
    "seed = 1234\n",
    "# Percentage of data to use for testing\n",
    "test_frac = 0.3\n",
    "\n",
    "\n",
    "#####################################\n",
    "# --- (2) ENCODER/MODEL/LOADER --- #\n",
    "\n",
    "# (i) Set up feature transformer pipeline\n",
    "enc_fac = Pipeline(steps=[('ohe', OneHotEncoder(drop=None,sparse_output=False, handle_unknown='ignore'))])\n",
    "sel_fac = make_column_selector(pattern='^fac\\\\_')\n",
    "enc_num = Pipeline(steps=[('impute', SimpleImputer(strategy='median')), \n",
    "                        ('scale', StandardScaler())])\n",
    "sel_num = make_column_selector(pattern='^num\\\\_')\n",
    "# Combine both\n",
    "enc_df = ColumnTransformer(transformers=[('ohe', enc_fac, sel_fac),('s', enc_num, sel_num)])\n",
    "enc_df.set_output(transform='pandas')  # Ensure output is a DataFrame\n",
    "\n",
    "# (ii) Run on datasets\n",
    "senc = surv_util()\n",
    "loader = SurvLoader()\n",
    "\n",
    "# (iii) Set up the models\n",
    "# model = CoxnetSurvivalAnalysis(normalize=True)\n",
    "model = RandomSurvivalForest(n_estimators=100, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# --- (3) LOOP OVER DATASETS --- #\n",
    "\n",
    "# (i) Initialize results holder and loop over datasets\n",
    "n_ds = len(loader.df_ds)\n",
    "holder_cindex = []\n",
    "for i, r in loader.df_ds.iterrows():\n",
    "    is_td, ds = r['is_td'], r['ds']\n",
    "    if is_td:\n",
    "        continue\n",
    "    print('Dataset %s (%i of %i)' % (ds, i+1, n_ds))\n",
    "    df = loader.load_dataset(ds)['df']\n",
    "    # Split based on both the event rate and unique IDs\n",
    "    df_train, df_test = stratified_group_split(df=df, group_col='pid', \n",
    "                            stratify_col='event', test_frac=test_frac, seed=seed)\n",
    "    assert not df_train['pid'].isin(df_test['pid']).any(), \\\n",
    "        'Training and test sets must not overlap in patient IDs.'\n",
    "    # Fit encoder\n",
    "    enc_df.fit(df_train)\n",
    "    # Transform data\n",
    "    X_train = enc_df.transform(df_train)\n",
    "    assert X_train.columns.str.split('\\\\_{1,2}', expand=True).to_frame(False)[1].isin(['fac','num']).all(), 'Expected feature names to be prefixed with \"fac_\" or \"num_\"'\n",
    "    X_test = enc_df.transform(df_test)\n",
    "    # Set up Surv object for static model and fit\n",
    "    So_train = senc.from_arrays(df_train['event'].astype(bool), df_train['time'])\n",
    "    model.fit(X=X_train, y=So_train)\n",
    "    # Get test prediction\n",
    "    scores_test = model.predict(X_test)\n",
    "    # Prepare test data for concordance calculation\n",
    "    res_test = df_test[['pid','event','time']].assign(scores=scores_test)\n",
    "    # Generate results and bootstrap concordance index\n",
    "    res_cindex = bootstrap_concordance_index(res_test, 'pid', 'event', 'time', 'scores', 'time2', n_bs, alpha, is_td=is_td)\n",
    "    res_cindex.insert(0, 'ds', ds) \n",
    "    res_cindex.insert(1, 'is_td', is_td)  # Add dataset and type\n",
    "    holder_cindex.append(res_cindex)\n",
    "\n",
    "# (ii) Merge results\n",
    "df_cindex = pd.concat(holder_cindex, ignore_index=True, axis=0)\n",
    "ds_ord = df_cindex.sort_values('cindex')['ds'].values\n",
    "df_cindex['ds'] = pd.Categorical(df_cindex['ds'], ds_ord)\n",
    "\n",
    "path_df = os.path.join(dir_sim, 'rsf_cindex.csv')\n",
    "df_cindex.to_csv(path_df, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7249643",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# --- (4) PLOT RESULTS --- #\n",
    "\n",
    "# (i) Plot concordance index\n",
    "gg_cindex = (pn.ggplot(df_cindex, pn.aes(y='cindex',x='ds', color='is_td')) + \n",
    "    pn.theme_bw() + pn.coord_flip() + \n",
    "    pn.geom_point(size=2) + \n",
    "    pn.geom_linerange(pn.aes(ymin='lb', ymax='ub')) + \n",
    "    pn.labs(y='Concordance') + \n",
    "    pn.scale_color_discrete(name='Time-varying covariates') +\n",
    "    pn.geom_hline(yintercept=0.5,linetype='--', color='black') + \n",
    "    pn.theme(axis_title_y=pn.element_blank()))\n",
    "path_fig = os.path.join(dir_sim, 'rsf_index.png')\n",
    "gg_cindex.save(path_fig, height=10, width=5)\n",
    "\n",
    "\n",
    "print('~~~ The SurvSet.sim_run module was successfully executed ~~~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacf169",
   "metadata": {},
   "source": [
    "### Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e49acf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cindex = pd.read_csv(\"results_survset/rsf_cindex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba70861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loader.df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abed2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Convert both to string\n",
    "df[\"ds\"] = df[\"ds\"].astype(str)\n",
    "df_cindex[\"ds\"] = df_cindex[\"ds\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed7a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.set_index(\"ds\").join(df_cindex.set_index(\"ds\").drop(\"is_td\", axis=1), how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3824ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_td</th>\n",
       "      <th>n</th>\n",
       "      <th>n_fac</th>\n",
       "      <th>n_ohe</th>\n",
       "      <th>n_num</th>\n",
       "      <th>cindex</th>\n",
       "      <th>lb</th>\n",
       "      <th>ub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>phpl04K8a</th>\n",
       "      <td>False</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.616717</td>\n",
       "      <td>0.567722</td>\n",
       "      <td>0.659190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhc</th>\n",
       "      <td>False</td>\n",
       "      <td>5735</td>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>0.707549</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.717386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bergamaschi</th>\n",
       "      <td>False</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.561937</td>\n",
       "      <td>0.848206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smarto</th>\n",
       "      <td>False</td>\n",
       "      <td>3873</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.690374</td>\n",
       "      <td>0.661732</td>\n",
       "      <td>0.721616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support2</th>\n",
       "      <td>False</td>\n",
       "      <td>9105</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>0.823342</td>\n",
       "      <td>0.819199</td>\n",
       "      <td>0.827998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             is_td     n  n_fac  n_ohe  n_num    cindex        lb        ub\n",
       "ds                                                                         \n",
       "phpl04K8a    False   442      1      1     20  0.616717  0.567722  0.659190\n",
       "rhc          False  5735     31     51     22  0.707549  0.695597  0.717386\n",
       "Bergamaschi  False    82      0      0     10  0.709677  0.561937  0.848206\n",
       "smarto       False  3873      9     17     17  0.690374  0.661732  0.721616\n",
       "support2     False  9105     11     41     24  0.823342  0.819199  0.827998"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[(temp.n_num >= 10) & (temp.n_num < 30)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
